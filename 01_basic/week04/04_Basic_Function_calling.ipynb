{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Understanding Function Calling with OpenAI API (Function Tool Calling)\n",
        "\n",
        "Welcome to this tutorial on **Function Calling** with the OpenAI API! This powerful feature allows you to connect large language models to external tools by enabling them to call specific functions you define. By the end of this lesson, you'll understand how to build more dynamic and capable applications like AI agents, chatbots, and smart automation systems.\n",
        "\n",
        "### What is Function Calling?\n",
        "\n",
        "Function calling lets the model intelligently decide when to call a function you've provided based on the user's prompt. For example, if a user asks, \"What's the weather in London?\", you can have a `get_weather` function that the model can choose to call. The process works like this:\n",
        "\n",
        "1.  **You define a function** and provide its description to the model.\n",
        "2.  The model **analyzes the user's prompt** and determines if it should call your function.\n",
        "3.  If it decides to, the model **returns a JSON object** with the function name and the arguments to use.\n",
        "4.  You **execute the function** with those arguments and send the result back to the model.\n",
        "5.  The model uses this information to **generate a final response** to the user.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Setup: Installing Libraries\n",
        "\n",
        "First, we need to install the necessary Python libraries. We'll be using `openai` for interacting with the API and `python-dotenv` for managing our API key securely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook cleaned.\n"
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "import sys\n",
        "\n",
        "def clean_notebook():\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    print(\"Notebook cleaned.\")\n",
        "\n",
        "# Install the required packages\n",
        "!pip install openai python-dotenv\n",
        "\n",
        "# Clean up the notebook output\n",
        "clean_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë Loading Environment Variables\n",
        "\n",
        "To keep our API key secure, we'll store it in a `.env` file and load it into our environment. Make sure you have a file named `.env` in the same directory with your `OPENAI_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Initializing the OpenAI Client\n",
        "\n",
        "Now, let's create an instance of the OpenAI client. We'll use this client to make requests to the API. We are specifying the model we want to use, in this case, `gpt-4.1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client with the API key\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "model_name = \"gpt-4.1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òÄÔ∏è Example: A Mock Weather Function\n",
        "\n",
        "Here, we'll define a simple function called `get_weather`. In a real-world application, this function would call a weather API. For this example, it will just return a fixed string. This helps us focus on the function calling mechanism itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the mock function\n",
        "def get_weather(location):\n",
        "    \"\"\"A mock function to get the current temperature.\"\"\"\n",
        "    return f\"The current temperature in {location} is 72¬∞F.\"\n",
        "\n",
        "# Define the 'tool' for the model to use\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current temperature for a given location.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and country, e.g., Bogot√°, Colombia\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üó£Ô∏è Making the First API Call\n",
        "\n",
        "Now, let's ask a question that should trigger our `get_weather` function. We'll send the user's query to the model and tell it about the tools it can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_y37dwXaMUvmD892SzXeG6uKf', function=Function(arguments='{\"location\":\"Paris, France\"}', name='get_weather'), type='function')])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The user's query\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}]\n",
        "\n",
        "# Make the first API call\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"  # Let the model decide whether to call a function\n",
        ")\n",
        "\n",
        "# Get the model's response message\n",
        "response_message = response.choices[0].message\n",
        "response_message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Analyzing the Model's Response\n",
        "\n",
        "Let's inspect the response. If the model decided to call a function, the `content` of the message will be `None`, and it will include `tool_calls` with the function name and arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's response: None\n",
            "Function call: get_weather with arguments {'location': 'Paris, France'}\n"
          ]
        }
      ],
      "source": [
        "# Display the initial response from the model\n",
        "print(\"Model's response:\", response_message.content)\n",
        "\n",
        "# Check if the model wants to call our function\n",
        "if response_message.tool_calls:\n",
        "    tool_call = response_message.tool_calls[0]\n",
        "    function_name = tool_call.function.name\n",
        "    function_args = json.loads(tool_call.function.arguments)\n",
        "    print(f\"Function call: {function_name} with arguments {function_args}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Testing with Multiple Questions\n",
        "\n",
        "To see how well the model distinguishes between different types of questions, let's test it with a list of queries. Some of these should trigger our `get_weather` function, while others should be answered directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Query: ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏õ‡∏≤‡∏£‡∏µ‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': 'Paris, France'}\n",
            "Function response: The current temperature in Paris, France is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏ô‡∏ô‡∏¥‡∏ß‡∏¢‡∏≠‡∏£‡πå‡∏Å‡∏ã‡∏¥‡∏ï‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': 'New York City, USA'}\n",
            "Function response: The current temperature in New York City, USA is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡πÅ‡∏°‡∏ß‡∏ä‡∏≠‡∏ö‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£?\n",
            "Initial Model's response content: ‡πÅ‡∏°‡∏ß‡∏ä‡∏≠‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡∏™‡∏π‡∏á ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏°‡∏ß‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ (‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡πÅ‡∏´‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏µ‡∏¢‡∏Å) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏™‡∏±‡∏ï‡∏ß‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏Å‡πà ‡∏õ‡∏•‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏ß‡∏±‡∏ß ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏° ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ ‡πÅ‡∏°‡∏ß‡∏¢‡∏±‡∏á‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏∏‡∏Å ‡πÑ‡∏Ç‡πà ‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏õ‡∏•‡∏≤‡∏ó‡∏π‡∏ô‡πà‡∏≤‡∏™‡∏î‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏® ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÅ‡∏°‡∏ß ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡πá‡∏≠‡∏Å‡πÇ‡∏Å‡πÅ‡∏•‡∏ï ‡∏´‡∏±‡∏ß‡∏´‡∏≠‡∏° ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡πÄ‡∏ó‡∏µ‡∏¢‡∏°\n",
            "\n",
            "‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡πÅ‡∏°‡∏ß‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏õ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡πÅ‡∏°‡∏ß‡∏ß‡πà‡∏≤‡πÄ‡∏Ç‡∏≤‡∏ä‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': '‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß, ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô'}\n",
            "Function response: The current temperature in ‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß, ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏ö‡∏≠‡∏Å‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡∏•‡∏≠‡∏ô‡∏î‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': 'London, UK'}\n",
            "Function response: The current temperature in London, UK is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ö‡πÇ‡∏Å‡∏ï‡∏≤ ‡πÇ‡∏Ñ‡∏•‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡∏¢\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': '‡πÇ‡∏ö‡πÇ‡∏Å‡∏ï‡∏≤ ‡πÇ‡∏Ñ‡∏•‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡∏¢'}\n",
            "Function response: The current temperature in ‡πÇ‡∏ö‡πÇ‡∏Å‡∏ï‡∏≤ ‡πÇ‡∏Ñ‡∏•‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡∏¢ is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ã‡∏¥‡∏î‡∏ô‡∏µ‡∏¢‡πå‡∏£‡πâ‡∏≠‡∏ô‡πÑ‡∏´‡∏°?\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': 'Sydney, Australia'}\n",
            "Function response: The current temperature in Sydney, Australia is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏•‡∏¥‡∏ô\n",
            "Initial Model's response content: None\n",
            "Function call: get_weather with arguments {'location': 'Berlin, Germany'}\n",
            "Function response: The current temperature in Berlin, Germany is 72¬∞F.\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡∏™‡∏≠‡∏á‡∏ö‡∏ß‡∏Å‡∏™‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\n",
            "Initial Model's response content: ‡∏™‡∏≠‡∏á‡∏ö‡∏ß‡∏Å‡∏™‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏™‡∏µ‡πà\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
            "Initial Model's response content: ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏£‡∏∏‡∏á‡∏õ‡∏≤‡∏£‡∏µ‡∏™ (Paris) ‡∏Ñ‡πà‡∏∞\n",
            "--------------------------------------------------\n",
            "\n",
            "Test Query: ‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏•‡∏Å‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢\n",
            "Initial Model's response content: ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô! ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏•‡∏Å‡∏™‡∏±‡πâ‡∏ô ‡πÜ:\n",
            "\n",
            "‡∏ó‡∏≥‡πÑ‡∏°‡∏ô‡∏±‡∏Å‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ñ‡∏∂‡∏á‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏õ‡∏µ‡∏¢‡πÇ‡∏ô‡∏Å‡∏±‡∏ö‡∏õ‡∏•‡∏≤‡∏ó‡∏π?\n",
            "‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡πÉ‡∏´‡πâ \"‡∏ó‡∏π‡∏ô\" ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏≤‡∏Å!\n",
            "\n",
            "‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏¢‡∏¥‡πâ‡∏°‡∏ô‡∏∞! üòÑ\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()  # Assume API key is set\n",
        "\n",
        "# Our trusty mock function\n",
        "def get_weather(location):\n",
        "    return f\"The current temperature in {location} is 72¬∞F.\"\n",
        "\n",
        "# The tool definition remains the same\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current temperature for a given location.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and country, e.g., Bogot√°, Colombia\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# A list of test questions in Thai\n",
        "test_questions = [\n",
        "    \"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏õ‡∏≤‡∏£‡∏µ‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\",\n",
        "    \"‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏ô‡∏ô‡∏¥‡∏ß‡∏¢‡∏≠‡∏£‡πå‡∏Å‡∏ã‡∏¥‡∏ï‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\",\n",
        "    \"‡πÅ‡∏°‡∏ß‡∏ä‡∏≠‡∏ö‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£?\",\n",
        "    \"‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\",\n",
        "    \"‡∏ö‡∏≠‡∏Å‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡∏•‡∏≠‡∏ô‡∏î‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢\",\n",
        "    \"‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ö‡πÇ‡∏Å‡∏ï‡∏≤ ‡πÇ‡∏Ñ‡∏•‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡∏¢\",\n",
        "    \"‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ã‡∏¥‡∏î‡∏ô‡∏µ‡∏¢‡πå‡∏£‡πâ‡∏≠‡∏ô‡πÑ‡∏´‡∏°?\",\n",
        "    \"‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏•‡∏¥‡∏ô\",\n",
        "    \"‡∏™‡∏≠‡∏á‡∏ö‡∏ß‡∏Å‡∏™‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\",\n",
        "    \"‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\",\n",
        "    \"‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏•‡∏Å‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢\"\n",
        "]\n",
        "\n",
        "# Loop through each question and see how the model responds\n",
        "for query in test_questions:\n",
        "    messages = [{\"role\": \"user\", \"content\": query}]\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "    \n",
        "    response_message = response.choices[0].message\n",
        "    \n",
        "    print(f\"Test Query: {query}\")\n",
        "    print(\"Initial Model's response content:\", response_message.content)\n",
        "    \n",
        "    if response_message.tool_calls:\n",
        "        tool_call = response_message.tool_calls[0]\n",
        "        function_name = tool_call.function.name\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        print(f\"Function call: {function_name} with arguments {function_args}\")\n",
        "        \n",
        "        if function_name == \"get_weather\":\n",
        "            function_response = get_weather(**function_args)\n",
        "            print(\"Function response:\", function_response)\n",
        "            \n",
        "    print(\"-\" * 50)\n",
        "    print()  # Add a newline for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multiple Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "model_name = \"gpt-4.1\"    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define mock functions\n",
        "def get_weather(location):\n",
        "    \"\"\"Mock weather function - in real scenario, call weather API\"\"\"\n",
        "    weather_data = {\n",
        "        \"Paris, France\": \"Sunny, 22¬∞C\",\n",
        "        \"Bangkok, Thailand\": \"Cloudy, 28¬∞C\", \n",
        "        \"New York, USA\": \"Rainy, 18¬∞C\",\n",
        "        \"Tokyo, Japan\": \"Partly cloudy, 25¬∞C\"\n",
        "    }\n",
        "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
        "\n",
        "def get_time(location):\n",
        "    \"\"\"Mock time function - in real scenario, call timezone API\"\"\"\n",
        "    time_data = {\n",
        "        \"Paris, France\": \"14:30 CET\",\n",
        "        \"Bangkok, Thailand\": \"20:30 ICT\",\n",
        "        \"New York, USA\": \"08:30 EST\", \n",
        "        \"Tokyo, Japan\": \"22:30 JST\"\n",
        "    }\n",
        "    return time_data.get(location, f\"Time data not available for {location}\")\n",
        "\n",
        "def get_exchange_rate(from_currency, to_currency):\n",
        "    \"\"\"Mock exchange rate function\"\"\"\n",
        "    rates = {\n",
        "        (\"USD\", \"EUR\"): 0.85,\n",
        "        (\"USD\", \"THB\"): 33.50,\n",
        "        (\"EUR\", \"USD\"): 1.18,\n",
        "        (\"EUR\", \"THB\"): 39.40\n",
        "    }\n",
        "    rate = rates.get((from_currency, to_currency))\n",
        "    if rate:\n",
        "        return f\"1 {from_currency} = {rate} {to_currency}\"\n",
        "    else:\n",
        "        return f\"Exchange rate not available for {from_currency} to {to_currency}\"\n",
        "\n",
        "# Define tools\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get current weather for a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"City and country e.g. Paris, France\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\", \n",
        "        \"function\": {\n",
        "            \"name\": \"get_time\",\n",
        "            \"description\": \"Get current time for a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"City and country e.g. Paris, France\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_exchange_rate\", \n",
        "            \"description\": \"Get exchange rate between two currencies\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"from_currency\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Source currency code e.g. USD\"\n",
        "                    },\n",
        "                    \"to_currency\": {\n",
        "                        \"type\": \"string\", \n",
        "                        \"description\": \"Target currency code e.g. EUR\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"from_currency\", \"to_currency\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Function mapping\n",
        "available_functions = {\n",
        "    \"get_weather\": get_weather,\n",
        "    \"get_time\": get_time, \n",
        "    \"get_exchange_rate\": get_exchange_rate\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': \"I'm planning a trip to Paris and Bangkok. Can you tell me the weather and current time in both cities? Also, what's the exchange rate from USD to EUR and USD to THB?\"}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# User query that might trigger multiple function calls\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"I'm planning a trip to Paris and Bangkok. Can you tell me the weather and current time in both cities? Also, what's the exchange rate from USD to EUR and USD to THB?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Initial Response ===\n",
            "Content: None\n",
            "Tool calls: 6\n",
            "\n",
            "=== Processing Tool Calls ===\n",
            "Tool call: get_weather with arguments {\"location\": \"Paris, France\"}\n",
            "Function response for get_weather: Sunny, 22¬∞C\n",
            "--------------------------------------------------\n",
            "Tool call: get_weather with arguments {\"location\": \"Bangkok, Thailand\"}\n",
            "Function response for get_weather: Cloudy, 28¬∞C\n",
            "--------------------------------------------------\n",
            "Tool call: get_time with arguments {\"location\": \"Paris, France\"}\n",
            "Function response for get_time: 14:30 CET\n",
            "--------------------------------------------------\n",
            "Tool call: get_time with arguments {\"location\": \"Bangkok, Thailand\"}\n",
            "Function response for get_time: 20:30 ICT\n",
            "--------------------------------------------------\n",
            "Tool call: get_exchange_rate with arguments {\"from_currency\": \"USD\", \"to_currency\": \"EUR\"}\n",
            "Function response for get_exchange_rate: 1 USD = 0.85 EUR\n",
            "--------------------------------------------------\n",
            "Tool call: get_exchange_rate with arguments {\"from_currency\": \"USD\", \"to_currency\": \"THB\"}\n",
            "Function response for get_exchange_rate: 1 USD = 33.5 THB\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# First API call\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls\n",
        "\n",
        "print(\"=== Initial Response ===\")\n",
        "print(f\"Content: {response_message.content}\")\n",
        "print(f\"Tool calls: {len(tool_calls) if tool_calls else 0}\")\n",
        "print()\n",
        "\n",
        "# Add the assistant's response to messages (including tool calls)\n",
        "messages.append({\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": response_message.content,\n",
        "    \"tool_calls\": tool_calls\n",
        "})\n",
        "\n",
        "# Process tool calls if they exist\n",
        "if tool_calls:\n",
        "    print(\"=== Processing Tool Calls ===\")\n",
        "    \n",
        "    for tool_call in tool_calls:\n",
        "        print(f\"Tool call: {tool_call.function.name} with arguments {tool_call.function.arguments}\")\n",
        "        \n",
        "        function_name = tool_call.function.name\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        \n",
        "        if function_name in available_functions:\n",
        "            # Execute the function\n",
        "            function_response = available_functions[function_name](**function_args)\n",
        "            print(f\"Function response for {function_name}: {function_response}\")\n",
        "            \n",
        "            # Add the function response to messages\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": str(function_response)\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Function {function_name} not found.\")\n",
        "            \n",
        "            # Add error response\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": f\"Error: Function {function_name} not available\"\n",
        "            })\n",
        "        \n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': \"I'm planning a trip to Paris and Bangkok. Can you tell me the weather and current time in both cities? Also, what's the exchange rate from USD to EUR and USD to THB?\"},\n",
              " {'role': 'assistant',\n",
              "  'content': None,\n",
              "  'tool_calls': [ChatCompletionMessageToolCall(id='call_YDQ0iagq0bbv9hzjGBg188t3', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_weather'), type='function'),\n",
              "   ChatCompletionMessageToolCall(id='call_VsMNvZ6lXU9wgGDDLgwMHIoo', function=Function(arguments='{\"location\": \"Bangkok, Thailand\"}', name='get_weather'), type='function'),\n",
              "   ChatCompletionMessageToolCall(id='call_fC32r7sLKcuLDqhrKTba2UqI', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_time'), type='function'),\n",
              "   ChatCompletionMessageToolCall(id='call_l8XVSt5h06Zo3JiNcfuPZ0qD', function=Function(arguments='{\"location\": \"Bangkok, Thailand\"}', name='get_time'), type='function'),\n",
              "   ChatCompletionMessageToolCall(id='call_gsfOThHEhrDFbaLKVA1Lpm3Q', function=Function(arguments='{\"from_currency\": \"USD\", \"to_currency\": \"EUR\"}', name='get_exchange_rate'), type='function'),\n",
              "   ChatCompletionMessageToolCall(id='call_vGM1QvBXVgMx0NqWQ2GpNbOd', function=Function(arguments='{\"from_currency\": \"USD\", \"to_currency\": \"THB\"}', name='get_exchange_rate'), type='function')]},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_YDQ0iagq0bbv9hzjGBg188t3',\n",
              "  'content': 'Sunny, 22¬∞C'},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_VsMNvZ6lXU9wgGDDLgwMHIoo',\n",
              "  'content': 'Cloudy, 28¬∞C'},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_fC32r7sLKcuLDqhrKTba2UqI',\n",
              "  'content': '14:30 CET'},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_l8XVSt5h06Zo3JiNcfuPZ0qD',\n",
              "  'content': '20:30 ICT'},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_gsfOThHEhrDFbaLKVA1Lpm3Q',\n",
              "  'content': '1 USD = 0.85 EUR'},\n",
              " {'role': 'tool',\n",
              "  'tool_call_id': 'call_vGM1QvBXVgMx0NqWQ2GpNbOd',\n",
              "  'content': '1 USD = 33.5 THB'}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Final Response ===\n",
            "Here is the current information for your trip to Paris and Bangkok:\n",
            "\n",
            "**Paris, France:**\n",
            "- Weather: Sunny, 22¬∞C\n",
            "- Current Time: 14:30 CET\n",
            "- Exchange Rate: 1 USD = 0.85 EUR\n",
            "\n",
            "**Bangkok, Thailand:**\n",
            "- Weather: Cloudy, 28¬∞C\n",
            "- Current Time: 20:30 ICT\n",
            "- Exchange Rate: 1 USD = 33.5 THB\n",
            "\n",
            "Let me know if there's anything else I can help with for your trip!\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "# Make a second API call to get the final response with all tool results\n",
        "final_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(\"=== Final Response ===\")\n",
        "print(final_response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
